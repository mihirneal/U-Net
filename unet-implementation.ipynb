{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nfrom PIL import Image\nimport csv\nimport random\nimport cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segregating the dataset.\npath = \"/kaggle/input/satellite-images-of-water-bodies/Water Bodies Dataset\"\nimg_path = os.path.join(path, \"Images\")\nimg_list = os.listdir(img_path)\ntc = int(len(img_list) * 0.8)\ntrain_img = img_list[:tc]\ntest_img = img_list[tc:]\ntrain_img[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WaterBodies():\n    def __init__(self, path, img_list, transform = None):\n        self.path = path\n        self.img_list = img_list\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.img_list)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(path, \"Images\")\n        mask_path = os.path.join(path, \"Masks\")\n        satImgPath = os.path.join(img_path, self.img_list[idx])\n        maskImgPath = os.path.join(mask_path, self.img_list[idx])\n        satImg = Image.open(satImgPath)\n        maskImg = Image.open(maskImgPath)\n        \n        if self.transform:\n            satImg = self.transform(satImg)\n            maskImg = self.transform(maskImg)\n            \n        return satImg, maskImg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_transform = transforms.Compose([\n    transforms.Resize((550, 550)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"satTrain = WaterBodies(path, train_img, transform=img_transform)\nsatTest = WaterBodies(path, test_img, transform=img_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=satTrain, batch_size = 16, shuffle=True)\ntest_loader = DataLoader(dataset=satTest, batch_size = 16, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing dataset\nimport matplotlib.pyplot as plt\n\nimg, msk = satTrain[0]\nplt.imshow(img.numpy().transpose((1, 2, 0)))\n# plt.imshow(msk.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convLayer(in_channels, out_channels):\n    conv = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size = 3),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(out_channels, out_channels, kernel_size = 3),\n        nn.ReLU(inplace=True)\n    )\n    return conv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_tensor(source, target):\n    _,_,h,w = target.shape\n    source = transforms.CenterCrop([h, w])(source)\n    return source","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concat_tensor(target, skip):\n    target = torch.cat([target, skip], axis=1)\n    return target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        self.conv1 = convLayer(3, 64)\n        self.maxPoolLayer = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = convLayer(64, 128)\n        self.conv3 = convLayer(128, 256) \n        self.conv4 = convLayer(256, 512)\n        self.conv5 = convLayer(512, 1024)\n        self.conv6 = convLayer(1024, 512)\n        self.conv7 = convLayer(512, 256)\n        self.conv8 = convLayer(256, 128) \n        self.conv9 = convLayer(128, 64)\n        self.upConv1 = nn.ConvTranspose2d(1024, 512, 2)\n        self.upConv2 = nn.ConvTranspose2d(512, 256, 2)\n        self.upConv3 = nn.ConvTranspose2d(256, 128, 2)\n        self.upConv4 = nn.ConvTranspose2d(128, 64, 2)\n        self.upConv5 = nn.ConvTranspose2d(64, 3, 2)\n    \n    def forward(self, image):\n        x1 = self.conv1(image) \n        x2 = self.maxPoolLayer(x1)\n        x3 = self.conv2(x2) \n        x4 = self.maxPoolLayer(x3)\n        x5 = self.conv3(x4) \n        x6 = self.maxPoolLayer(x5)\n        x7 = self.conv4(x6) \n        x8 = self.maxPoolLayer(x7)\n        x9 = self.conv5(x8)\n        x = self.upConv1(x9)\n        y = concat_tensor(x, crop_tensor(x7, x))\n        x = self.conv6(y)\n        x = self.upConv2(x)\n        y = concat_tensor(x, crop_tensor(x5, x))\n        x = self.conv7(y)\n        x = self.upConv3(x)\n        y = concat_tensor(x, crop_tensor(x3, x))\n        x = self.conv8(y)\n        x = self.upConv4(x)\n        y = concat_tensor(x, crop_tensor(x1, x))\n        x = self.conv9(y)\n        x = self.upConv5(x)\n\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the Model\n\nx = torch.randn(2, 3, 527, 527)\nmodel = UNet()\noutput = model(x)\nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beta = 0.99\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum=beta)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_ep = 30\nfor ep in range(num_ep):\n    for img, msk in train_loader:\n        img = img.to(device)\n        msk = msk.to(device)\n        \n        optimizer.zero_grad()\n        output = model(img)\n        print(output.size(), msk.size())\n        loss = criterion(output, msk)\n        \n        loss.backward()\n        optimizer.step()\n        \n        _, predicted = torch.max(output.data, 1)\n        total_train += msk.nelement()\n        correct_train += predicted.eq(msk.data).sum().item()\n        train_accuracy = 100 * correct_train / total_train\n        \n        print(f'Epoch: [{ep + 1} / {num_ep}], Loss: {loss.item():.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pixel_accuracy(output, mask):\n    with torch.no_grad():\n        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n        correct = torch.eq(output, mask).int()\n        accuracy = float(correct.sum()) / float(correct.numel())\n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mIoU(pred_mask, mask, smooth=1e-10, n_classes=2):\n    with torch.no_grad():\n        pred_mask = nn.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n\n        iou_per_class = []\n        for clas in range(0, n_classes): #loop per pixel class\n            true_class = pred_mask == clas\n            true_label = mask == clas\n\n            if true_label.long().sum().item() == 0: #no exist label in this loop\n                iou_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n                union = torch.logical_or(true_class, true_label).sum().float().item()\n\n                iou = (intersect + smooth) / (union +smooth)\n                iou_per_class.append(iou)\n        return np.nanmean(iou_per_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing the Image Segmentation Models\n\nmodel.eval()\nmiou_list = []\npix_acc = []\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\nfor img, msk in test_loader:\n    with torch.no_grad():\n        img = img.to(device)\n        msk = msk.to(device)\n        img.unsqueeze(0)\n        msk.unsqueeze(0)\n        output = model(img)\n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n        \n        \n        #PixelAccuracy\n        pred, sc = pixel_accuracy(model, img, msk)\n        pix_acc.append(sc)\n        \n        #MIOU\n        pred, sc = mIOU(model, img, msk)\n        miou_list.append(sc)\n\n        \n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}